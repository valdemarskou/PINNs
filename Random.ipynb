{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Mini-Epoch Test ---\n",
    "\n",
    "# 1. Set the correction network to train mode (or eval mode if you want no dropout/batchnorm).\n",
    "correction_net.train()\n",
    "\n",
    "# 2. Get one batch (sample) from the DataLoader.\n",
    "data_iter = iter(data_loader)\n",
    "t_batch, output_batch = next(data_iter)\n",
    "\n",
    "# If batch_size=1, PyTorch adds a batch dimension.\n",
    "# Remove or index out that dimension if needed:\n",
    "t_instance = t_batch.squeeze(0)     # Now shape [num_timepoints]\n",
    "trajectory_gt = output_batch\n",
    "trajectory_gt = [state[1:-1] for state in trajectory_gt]     # If 'output_batch' is a list of length 1\n",
    "\n",
    "tN = t_instance[-1]\n",
    "psiInitial = output_batch[1]\n",
    "\n",
    "corrected_traj, solver_t = PRE_hybridSolver(tN,psiInitial, torchsolver.havercampCfun, torchsolver.havercampKfun, torchsolver.havercampthetafun, torchsolver.zeroFun, correction_net)\n",
    "\n",
    "\n",
    "loss = 0.0\n",
    "num_steps = len(solver_t)\n",
    "for j, s in enumerate(solver_t):\n",
    "    # interpolate_at_time(s, t_instance, trajectory_gt) must be defined by you\n",
    "    gt_state = interpolate_at_time(s, t_instance, trajectory_gt)\n",
    "    loss += torch.mean((corrected_traj[j] - gt_state) ** 2)\n",
    "\n",
    "loss = loss / num_steps\n",
    "\n",
    "print(\"Mini-epoch loss (MSE):\", loss.item())\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
