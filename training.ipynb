{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/valdemarskou/PINNs/blob/main/training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/valdemarskou/PINNs"
      ],
      "metadata": {
        "id": "Gp0USEqkzLrV",
        "outputId": "54671416-a72f-4753-9353-512cff13b475",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'PINNs' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "w7imzlumyPjl"
      },
      "outputs": [],
      "source": [
        "# @title imports\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits import mplot3d\n",
        "\n",
        "\n",
        "\n",
        "import torch_mpfd_solver as torchsolver\n",
        "\n",
        "from training_data import generateData\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import random\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import ast\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "cellView": "form",
        "id": "NSq2hcWByPjn"
      },
      "outputs": [],
      "source": [
        "# @title clean and convert data\n",
        "def clean_and_convert_t(s):\n",
        "    s = s.strip()  # Remove leading/trailing whitespace (including \\r\\n)\n",
        "    s = s.replace(\"\\r\", \"\").replace(\"\\n\", \"\")  # Remove any remaining newline artifacts\n",
        "\n",
        "    match = re.search(r\"tensor\\((\\[.*?\\])\\)\", s)  # Extract only the list part\n",
        "    if match:\n",
        "        return torch.tensor(ast.literal_eval(match.group(1)), dtype=torch.float32)\n",
        "    else:\n",
        "        raise ValueError(f\"Unexpected format for t: {s}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def clean_and_convert_output(s):\n",
        "    s = s.strip()  # Remove leading/trailing whitespace (including \\r\\n)\n",
        "    s = s.replace(\"\\r\", \"\").replace(\"\\n\", \"\")  # Remove newline artifacts\n",
        "\n",
        "    # Extract all array([...]) groups inside the list\n",
        "    matches = re.findall(r\"array\\(\\s*(\\[.*?\\])\", s)  # Find all arrays inside the string\n",
        "    if matches:\n",
        "        # Convert each extracted list into a PyTorch tensor\n",
        "        return [torch.tensor(ast.literal_eval(arr), dtype=torch.float32) for arr in matches]\n",
        "    else:\n",
        "        raise ValueError(f\"Unexpected format for output: {s}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "cellView": "form",
        "id": "1mIvWvfHyPjo"
      },
      "outputs": [],
      "source": [
        "# @title interpolater\n",
        "def interpolate_at_time(s, t, v):\n",
        "\n",
        "    # If s is before or after the available timepoints, we simply return the end values.\n",
        "    if s <= t[0]:\n",
        "        return v[0] if isinstance(v, list) else v[0]\n",
        "    if s >= t[-1]:\n",
        "        return v[-1] if isinstance(v, list) else v[-1]\n",
        "\n",
        "    # Find the segment where s lies, i.e. find index i such that t[i] <= s <= t[i+1]\n",
        "    for i in range(len(t) - 1):\n",
        "        if t[i] <= s <= t[i+1]:\n",
        "            # Compute the interpolation factor alpha: 0 when s==t[i], 1 when s==t[i+1]\n",
        "            alpha = (s - t[i]) / (t[i+1] - t[i])\n",
        "            # Use torch.lerp (linear interpolation): lerp(start, end, weight)\n",
        "            if isinstance(v, list):\n",
        "                return torch.lerp(v[i], v[i+1], alpha)\n",
        "            else:\n",
        "                return torch.lerp(v[i], v[i+1], alpha)\n",
        "\n",
        "    # If s is not within any segment (shouldn't happen), raise an error.\n",
        "    raise ValueError(\"The timepoint s is not within the range of t.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "oIqlAuQCyPjo"
      },
      "outputs": [],
      "source": [
        "# @title load dataset\n",
        "class PDETrajectoryDataset(Dataset):\n",
        "\n",
        "    def __init__(self, csv_file):\n",
        "        self.df = pd.read_csv(csv_file)\n",
        "        # Convert the stored strings to proper tensors using your functions:\n",
        "        self.df[\"t\"] = self.df[\"t\"].apply(clean_and_convert_t)\n",
        "        self.df[\"output\"] = self.df[\"output\"].apply(clean_and_convert_output)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        # 'output' is assumed to be a list of tensors representing the PDE trajectory.\n",
        "        trajectory = row[\"output\"]\n",
        "        # h0 is the first element of the ground truth trajectory.\n",
        "        t = row[\"t\"]\n",
        "        # Optionally, you could also return the timepoints if needed (row[\"t\"]).\n",
        "        return t, trajectory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "cellView": "form",
        "id": "j-Co6PK4yPjp"
      },
      "outputs": [],
      "source": [
        "# @title define cnn\n",
        "class CorrectionCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CorrectionCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=8, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv1d(in_channels=8, out_channels=16, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv1d(in_channels=16, out_channels=12, kernel_size=3, padding=1)\n",
        "        self.conv4 = nn.Conv1d(in_channels=12, out_channels=1, kernel_size=3, padding=1)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Expect input x shape: (batch, length). Add channel dimension -> (batch, 1, length)\n",
        "        x = x.unsqueeze(1)\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = self.relu(self.conv3(x))\n",
        "        x = self.conv4(x)\n",
        "        # Remove the channel dimension, returning shape: (batch, length)\n",
        "        x = x.squeeze(1)\n",
        "        return x\n",
        "\n",
        "    # Utility to count parameters (for verification)\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "cellView": "form",
        "id": "YnPA1kIcyPjp"
      },
      "outputs": [],
      "source": [
        "# @title SOL hybrid solver\n",
        "\n",
        "def SOL_hybridSolver(tN,psiInitial,Cfun,Kfun,thetafun,sink, correction_net):\n",
        "    dt = 120.\n",
        "    zN = 40.\n",
        "    flag = 0\n",
        "\n",
        "    # Get the traditional solver information ready:\n",
        "\n",
        "    z,t,dts,dz,n,nt,zN,psi,psiB,psiT,pars = torchsolver.setup(dt,tN,zN,psiInitial,torchsolver.havercampSetpars)\n",
        "\n",
        "    psiList = []\n",
        "    psiList +=[psi]\n",
        "\n",
        "    if flag==0:\n",
        "        for j in range(1,nt):\n",
        "            uncorrectedTrajectory = torchsolver.dirichletOneStepModelRun(dts[j-1],dz,n,psiList[j-1],psiB[j-1],psiT[j-1],pars,Cfun,Kfun,thetafun,sink)\n",
        "            h_batch = uncorrectedTrajectory.unsqueeze(0)\n",
        "            correction = correction_net(h_batch)\n",
        "            psiList +=[uncorrectedTrajectory + correction.squeeze(0)]\n",
        "\n",
        "\n",
        "    return psiList,t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "cellView": "form",
        "id": "xnJZj2YNyPjq"
      },
      "outputs": [],
      "source": [
        "# @title PRE hybrid solver\n",
        "def PRE_hybridSolver(tN,psiInitial,Cfun,Kfun,thetafun,sink, correction_net):\n",
        "    dt = 120.\n",
        "    zN = 40.\n",
        "    flag = 0\n",
        "\n",
        "    # Get the traditional solver information ready:\n",
        "\n",
        "    z,t,dts,dz,n,nt,zN,psi,psiB,psiT,pars = torchsolver.setup(dt,tN,zN,psiInitial,torchsolver.havercampSetpars)\n",
        "\n",
        "\n",
        "    psiList = torchsolver.fullModelRun(dt,dts,dz,n,nt,psi,psiB,psiT,pars, Cfun,Kfun,thetafun,flag,sink)\n",
        "\n",
        "    psiList[1:] = [(h + correction_net(h.unsqueeze(0))).squeeze(0) for h in psiList[1:]]\n",
        "\n",
        "    return psiList,t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "cellView": "form",
        "id": "LENOnTVJyPjq"
      },
      "outputs": [],
      "source": [
        "# @title NN training procedure\n",
        "def train_hybrid_solver(hybridSolver,correction_net, data_loader, optimizer, num_epochs=10, checkpoint_interval=1):\n",
        "\n",
        "    correction_net.train()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0.0\n",
        "\n",
        "        for batch in data_loader:\n",
        "            # Each batch is assumed to be (t, output)\n",
        "            # For a batch_size=1, extract the single instance.\n",
        "            t_batch, output_batch = batch\n",
        "\n",
        "            t_instance = t_batch.squeeze(0)\n",
        "            trajectory_gt = output_batch\n",
        "            trajectory_gt = [state[1:-1] for state in trajectory_gt]\n",
        "            # Extract solver parameters:\n",
        "\n",
        "            tN = t_instance[-1]\n",
        "            psiInitial = output_batch[1]\n",
        "            # --- Call the hybrid solver ---\n",
        "\n",
        "            corrected_traj, solver_t = hybridSolver(tN, psiInitial, torchsolver.havercampCfun, torchsolver.havercampKfun, torchsolver.havercampthetafun, torchsolver.zeroFun, correction_net)\n",
        "\n",
        "            # --- Compute the loss ---\n",
        "            # For each time s in the solver's time discretization, interpolate the ground truth\n",
        "            # and compute the MSE with the corrected state.\n",
        "            loss = 0.0\n",
        "            num_steps = len(solver_t)\n",
        "            for j, s in enumerate(solver_t):\n",
        "                # interpolate_at_time returns the ground truth state at time s given the tuple (t_instance, trajectory_gt)\n",
        "                gt_state = interpolate_at_time(s, t_instance, trajectory_gt)\n",
        "                # Compute mean squared error for this time step:\n",
        "                loss += torch.mean((corrected_traj[j] - gt_state) ** 2)\n",
        "            loss = loss / num_steps  # average over all time steps\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss:.4f}\")\n",
        "\n",
        "        # Save checkpoint.\n",
        "        if (epoch + 1) % checkpoint_interval == 0:\n",
        "            checkpoint_path = f'correction_net_epoch_{epoch+1}.pth'\n",
        "            torch.save(correction_net.state_dict(), checkpoint_path)\n",
        "            print(f\"Saved checkpoint: {checkpoint_path}\")\n",
        "\n",
        "    final_path = 'correction_net_final.pth'\n",
        "    torch.save(correction_net.state_dict(), final_path)\n",
        "    print(f\"Saved final model weights as {final_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "Yb96sMIPyPjq"
      },
      "outputs": [],
      "source": [
        "# @title Data loader\n",
        "def custom_collate_fn(batch):\n",
        "    # If batch size is 1, just return the single tuple instead of a list with one element.\n",
        "    if len(batch) == 1:\n",
        "        return batch[0]\n",
        "    else:\n",
        "        ts, outputs = zip(*batch)\n",
        "        # For 't' assume all samples have the same shape, so you can stack them:\n",
        "        ts = torch.stack(ts, 0)\n",
        "        # 'outputs' will remain a tuple of the ground truth trajectories\n",
        "        return ts, list(outputs)\n",
        "\n",
        "csv_file = \"high_fidelity_training_data.csv\"  # Replace with your CSV file path\n",
        "dataset = PDETrajectoryDataset(csv_file)\n",
        "data_loader = DataLoader(dataset, batch_size=1,collate_fn=custom_collate_fn, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "x6_-FjQ4yPjr"
      },
      "outputs": [],
      "source": [
        "#correction_net = CorrectionCNN()\n",
        "#correction_net.load_state_dict(torch.load(\"correction_net_epoch_9.pth\"))\n",
        "#optimizer = optim.Adam(correction_net.parameters(), lr=0.01)\n",
        "#train_hybrid_solver(PRE_hybridSolver,correction_net, data_loader, optimizer, num_epochs=20, checkpoint_interval=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generateData(1)"
      ],
      "metadata": {
        "id": "y-wxvGkg0ml8",
        "outputId": "60dfdc4b-2469-4812-c99f-2a228a9216a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        }
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-ca073ea8354b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerateData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/training_data.py\u001b[0m in \u001b[0;36mgenerateData\u001b[0;34m(num_samples)\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mpsiInitial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpsiB\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpsiInitial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpsiT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mzN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpsi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpsiB\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpsiT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchsolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mzN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpsiInitial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorchsolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhavercampSetpars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mpsiList\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchsolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfullModelRun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpsi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpsiB\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpsiT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorchsolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhavercampCfun\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorchsolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhavercampKfun\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorchsolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhavercampthetafun\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mflag\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorchsolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeroFun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/torch_mpfd_solver.py\u001b[0m in \u001b[0;36msetup\u001b[0;34m(dt, tN, zN, psiInitial, setpars)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;31m#psiB = torch.tensor([psiInitial[0]], dtype=torch.float32)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m     \u001b[0mpsiB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpsiInitial\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m     \u001b[0mpsiT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpsiInitial\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1117\u001b[0m                 \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m             )\n\u001b[0;32m-> 1119\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kF-HRLmy1oaR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "pinn",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}