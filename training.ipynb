{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Gp0USEqkzLrV"
      },
      "outputs": [],
      "source": [
        "#!git clone https://github.com/valdemarskou/PINNs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "w7imzlumyPjl"
      },
      "outputs": [],
      "source": [
        "# @title imports\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits import mplot3d\n",
        "\n",
        "\n",
        "\n",
        "import cudatorch_mpfd_solver as torchsolver\n",
        "\n",
        "from training_data import generateData\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "import random\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import ast\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "cellView": "form",
        "id": "NSq2hcWByPjn"
      },
      "outputs": [],
      "source": [
        "# @title clean and convert data\n",
        "def clean_and_convert_t(s):\n",
        "    s = s.strip()  # Remove leading/trailing whitespace (including \\r\\n)\n",
        "    s = s.replace(\"\\r\", \"\").replace(\"\\n\", \"\")  # Remove any remaining newline artifacts\n",
        "\n",
        "    match = re.search(r\"tensor\\((\\[.*?\\])\\)\", s)  # Extract only the list part\n",
        "    if match:\n",
        "        return torch.tensor(ast.literal_eval(match.group(1)), dtype=torch.float32)\n",
        "    else:\n",
        "        raise ValueError(f\"Unexpected format for t: {s}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def clean_and_convert_output(s):\n",
        "    s = s.strip()  # Remove leading/trailing whitespace (including \\r\\n)\n",
        "    s = s.replace(\"\\r\", \"\").replace(\"\\n\", \"\")  # Remove newline artifacts\n",
        "\n",
        "    # Extract all array([...]) groups inside the list\n",
        "    matches = re.findall(r\"array\\(\\s*(\\[.*?\\])\", s)  # Find all arrays inside the string\n",
        "    if matches:\n",
        "        # Convert each extracted list into a PyTorch tensor\n",
        "        return [torch.tensor(ast.literal_eval(arr), dtype=torch.float32) for arr in matches]\n",
        "    else:\n",
        "        raise ValueError(f\"Unexpected format for output: {s}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "cellView": "form",
        "id": "1mIvWvfHyPjo"
      },
      "outputs": [],
      "source": [
        "# @title interpolation function (with device conversion)\n",
        "def interpolate_at_time(s, t, v):\n",
        "    \"\"\"\n",
        "    Interpolates the tensor trajectory (list of tensors) v at time s using the timepoints t.\n",
        "    All tensors are assumed to be on the correct device.\n",
        "    \"\"\"\n",
        "    if s <= t[0]:\n",
        "        return v[0].to(device) if isinstance(v[0], torch.Tensor) else v[0]\n",
        "    if s >= t[-1]:\n",
        "        return v[-1].to(device) if isinstance(v[-1], torch.Tensor) else v[-1]\n",
        "\n",
        "    # Find the segment where s lies, i.e. find index i such that t[i] <= s <= t[i+1]\n",
        "    for i in range(len(t) - 1):\n",
        "        if t[i] <= s <= t[i+1]:\n",
        "            # Compute the interpolation factor alpha: 0 when s==t[i], 1 when s==t[i+1]\n",
        "            alpha = (s - t[i]) / (t[i+1] - t[i])\n",
        "            # Use torch.lerp (linear interpolation): lerp(start, end, weight)\n",
        "            val = torch.lerp(v[i].to(device), v[i+1].to(device), alpha)\n",
        "            return val\n",
        "    raise ValueError(\"The timepoint s is not within the range of t.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "oIqlAuQCyPjo"
      },
      "outputs": [],
      "source": [
        "# @title load dataset\n",
        "class PDETrajectoryDataset(Dataset):\n",
        "\n",
        "    def __init__(self, csv_file):\n",
        "        self.df = pd.read_csv(csv_file)\n",
        "        # Convert the stored strings to proper tensors using your functions:\n",
        "        self.df[\"t\"] = self.df[\"t\"].apply(clean_and_convert_t)\n",
        "        self.df[\"output\"] = self.df[\"output\"].apply(clean_and_convert_output)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        # 'output' is assumed to be a list of tensors representing the PDE trajectory.\n",
        "        trajectory = [state.to(device) for state in row[\"output\"]]\n",
        "        # h0 is the first element of the ground truth trajectory.\n",
        "        t = row[\"t\"]\n",
        "        # Also ensure the timepoints are on device if needed (if they're tensors)\n",
        "        if isinstance(t, torch.Tensor):\n",
        "            t = t.to(device)\n",
        "        return t, trajectory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "j-Co6PK4yPjp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "outputId": "ba2dab49-8748-48de-a5f4-1d5875a82dc9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'# @title define cnn\\nclass CorrectionCNN(nn.Module):\\n    def __init__(self):\\n        super(CorrectionCNN, self).__init__()\\n        self.conv1 = nn.Conv1d(in_channels=1, out_channels=8, kernel_size=3, padding=1)\\n        self.conv2 = nn.Conv1d(in_channels=8, out_channels=16, kernel_size=3, padding=1)\\n        self.conv3 = nn.Conv1d(in_channels=16, out_channels=12, kernel_size=3, padding=1)\\n        self.conv4 = nn.Conv1d(in_channels=12, out_channels=1, kernel_size=3, padding=1)\\n        self.relu = nn.ReLU()\\n\\n    def forward(self, x):\\n        # Expect input x shape: (batch, length). Add channel dimension -> (batch, 1, length)\\n        x = x.unsqueeze(1)\\n        x = self.relu(self.conv1(x))\\n        x = self.relu(self.conv2(x))\\n        x = self.relu(self.conv3(x))\\n        x = self.conv4(x)\\n        # Remove the channel dimension, returning shape: (batch, length)\\n        x = x.squeeze(1)\\n        return x\\n\\n# Utility to count parameters (for verification)\\ndef count_parameters(model):\\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "'''# @title define cnn\n",
        "class CorrectionCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CorrectionCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=8, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv1d(in_channels=8, out_channels=16, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv1d(in_channels=16, out_channels=12, kernel_size=3, padding=1)\n",
        "        self.conv4 = nn.Conv1d(in_channels=12, out_channels=1, kernel_size=3, padding=1)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Expect input x shape: (batch, length). Add channel dimension -> (batch, 1, length)\n",
        "        x = x.unsqueeze(1)\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = self.relu(self.conv3(x))\n",
        "        x = self.conv4(x)\n",
        "        # Remove the channel dimension, returning shape: (batch, length)\n",
        "        x = x.squeeze(1)\n",
        "        return x\n",
        "\n",
        "# Utility to count parameters (for verification)\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Larger cnn\n",
        "\n",
        "class CorrectionCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CorrectionCNN, self).__init__()\n",
        "        # Increased channels for more parameters:\n",
        "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=24, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv1d(in_channels=24, out_channels=48, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv1d(in_channels=48, out_channels=40, kernel_size=3, padding=1)\n",
        "        self.conv4 = nn.Conv1d(in_channels=40, out_channels=1, kernel_size=3, padding=1)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Expect input x shape: (batch, length). Add channel dimension -> (batch, 1, length)\n",
        "        x = x.unsqueeze(1)\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = self.relu(self.conv3(x))\n",
        "        x = self.conv4(x)\n",
        "        # Remove the channel dimension, returning shape: (batch, length)\n",
        "        x = x.squeeze(1)\n",
        "        return x\n",
        "\n",
        "# Utility to count parameters (for verification)\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "# Instantiate the model and print the number of trainable parameters\n",
        "model = CorrectionCNN()\n",
        "print(\"Total trainable parameters:\", count_parameters(model))\n"
      ],
      "metadata": {
        "id": "deGf8HgFYeMY",
        "outputId": "6dd4e1ab-6a8c-4669-f61c-50fb9dce7447",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total trainable parameters: 9521\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "YnPA1kIcyPjp"
      },
      "outputs": [],
      "source": [
        "# @title SOL hybrid solver\n",
        "\n",
        "def SOL_hybridSolver(tN, psiInitial, Cfun, Kfun, thetafun, sink, correction_net):\n",
        "    dt = 120.\n",
        "    zN = 40.\n",
        "    flag = 0\n",
        "\n",
        "    # Get the traditional solver information ready:\n",
        "    z, t, dts, dz, n, nt, zN, psi, psiB, psiT, pars = torchsolver.setup(dt, tN, zN, psiInitial, torchsolver.havercampSetpars)\n",
        "    # Move psi and other tensors to device if they aren’t already (assuming torchsolver.setup returns CPU tensors)\n",
        "\n",
        "    psiList = []\n",
        "    psiList += [psi]\n",
        "\n",
        "    if flag == 0:\n",
        "        for j in range(1, nt):\n",
        "            uncorrectedTrajectory = torchsolver.dirichletOneStepModelRun(dts[j-1], dz, n, psiList[j-1], psiB[j-1], psiT[j-1], pars, Cfun, Kfun, thetafun, sink)\n",
        "            # Ensure uncorrectedTrajectory is on device\n",
        "            uncorrectedTrajectory = uncorrectedTrajectory.to(device)\n",
        "            h_batch = uncorrectedTrajectory.unsqueeze(0)\n",
        "            correction = correction_net(h_batch)\n",
        "            psiList += [uncorrectedTrajectory + correction.squeeze(0)]\n",
        "    return psiList, t\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "xnJZj2YNyPjq"
      },
      "outputs": [],
      "source": [
        "# @title PRE hybrid solver\n",
        "def PRE_hybridSolver(tN, psiInitial, Cfun, Kfun, thetafun, sink, correction_net):\n",
        "    dt = 120.\n",
        "    zN = 40.\n",
        "    flag = 0\n",
        "\n",
        "    # Get the traditional solver information ready:\n",
        "    z, t, dts, dz, n, nt, zN, psi, psiB, psiT, pars = torchsolver.setup(dt, tN, zN, psiInitial, torchsolver.havercampSetpars)\n",
        "    # Ensure tensors from setup are moved to the device\n",
        "    #psi = psi.to(device)\n",
        "    #psiB = psiB.to(device)\n",
        "    #psiT = psiT.to(device)\n",
        "\n",
        "    psiList = torchsolver.fullModelRun(dt, dts, dz, n, nt, psi, psiB, psiT, pars, Cfun, Kfun, thetafun, flag, sink)\n",
        "    # Apply correction network and ensure results are on device\n",
        "    psiList[1:] = [(h.to(device) + correction_net(h.unsqueeze(0)).to(device)).squeeze(0) for h in psiList[1:]]\n",
        "    return psiList, t\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "LENOnTVJyPjq"
      },
      "outputs": [],
      "source": [
        "# @title NN training procedure\n",
        "#%% Cell: NN training procedure\n",
        "def train_hybrid_solver(hybridSolver, correction_net, data_loader, optimizer, num_epochs=10, checkpoint_interval=1):\n",
        "    correction_net.train()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0.0\n",
        "\n",
        "        for batch in data_loader:\n",
        "            # Each batch is assumed to be (t, output)\n",
        "            t_batch, output_batch = batch\n",
        "\n",
        "            t_instance = t_batch.squeeze(0)\n",
        "            trajectory_gt = output_batch\n",
        "            # Removing boundary states and ensuring each tensor is on device\n",
        "            trajectory_gt = [state[1:-1].to(device) for state in trajectory_gt]\n",
        "\n",
        "            # Extract solver parameters:\n",
        "            tN = t_instance[-1]\n",
        "            psiInitial = output_batch[1]\n",
        "            # --- Call the hybrid solver ---\n",
        "            corrected_traj, solver_t = hybridSolver(tN, psiInitial, torchsolver.havercampCfun, torchsolver.havercampKfun, torchsolver.havercampthetafun, torchsolver.zeroFun, correction_net)\n",
        "\n",
        "            # --- Compute the loss ---\n",
        "            loss = 0.0\n",
        "            num_steps = len(solver_t)\n",
        "            for j, s in enumerate(solver_t):\n",
        "                # interpolate_at_time returns the ground truth state at time s given the tuple (t_instance, trajectory_gt)\n",
        "                gt_state = interpolate_at_time(s, t_instance, trajectory_gt)\n",
        "                # Compute mean squared error for this time step:\n",
        "                loss += torch.mean((corrected_traj[j] - gt_state) ** 2)\n",
        "            loss = loss / num_steps  # average over all time steps\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss:.4f}\")\n",
        "\n",
        "        # Save checkpoint.\n",
        "        if (epoch + 1) % checkpoint_interval == 0:\n",
        "            checkpoint_path = f'correction_net_epoch_{epoch+1}.pth'\n",
        "            torch.save(correction_net.state_dict(), checkpoint_path)\n",
        "            print(f\"Saved checkpoint: {checkpoint_path}\")\n",
        "\n",
        "    final_path = 'correction_net_final.pth'\n",
        "    torch.save(correction_net.state_dict(), final_path)\n",
        "    print(f\"Saved final model weights as {final_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "cellView": "form",
        "id": "Yb96sMIPyPjq"
      },
      "outputs": [],
      "source": [
        "# @title Data loader\n",
        "def custom_collate_fn(batch):\n",
        "    # If batch size is 1, just return the single tuple instead of a list with one element.\n",
        "    if len(batch) == 1:\n",
        "        return batch[0]\n",
        "    else:\n",
        "        ts, outputs = zip(*batch)\n",
        "        # For 't' assume all samples have the same shape, so you can stack them:\n",
        "        ts = torch.stack(ts, 0)\n",
        "        # 'outputs' will remain a tuple of the ground truth trajectories\n",
        "        return ts, list(outputs)\n",
        "\n",
        "csv_file = \"high_fidelity_training_data.csv\"  # Replace with your CSV file path\n",
        "dataset = PDETrajectoryDataset(csv_file)\n",
        "data_loader = DataLoader(dataset, batch_size=1,collate_fn=custom_collate_fn, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "x6_-FjQ4yPjr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f49519ce-8e9e-4555-bcb4-672d68b17f0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-42-6d637c6fd0e0>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  correction_net.load_state_dict(torch.load(\"correction_net_10kweights_example1final.pth\",map_location=torch.device('cpu')))\n"
          ]
        }
      ],
      "source": [
        "correction_net = CorrectionCNN()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "correction_net.to(device)\n",
        "# optional: load weights\n",
        "correction_net.load_state_dict(torch.load(\"correction_net_10kweights_example1final.pth\",map_location=torch.device('cpu')))\n",
        "optimizer = optim.Adam(correction_net.parameters(), lr=0.001)\n",
        "#train_hybrid_solver(PRE_hybridSolver,correction_net, data_loader, optimizer, num_epochs=20, checkpoint_interval=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kF-HRLmy1oaR",
        "outputId": "9b391975-db0d-4dd1-c44f-a74cb66e5ed3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/cudatorch_mpfd_solver.py:226: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  t = torch.hstack([t, torch.tensor(tN, device=device)])\n",
            "/content/cudatorch_mpfd_solver.py:229: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  psi = torch.tensor(psiInitial[1:-1], dtype=torch.float32, device=device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100, Loss: 2.0289\n",
            "Saved checkpoint: correction_net_epoch_1.pth\n"
          ]
        }
      ],
      "source": [
        "# @title Single element training\n",
        "\n",
        "\n",
        "# SOL = index 1\n",
        "# PRE = index 0\n",
        "\n",
        "\n",
        "#correction_net.load_state_dict(torch.load(\"correction_net_single_element_dataset.pth\"))\n",
        "\n",
        "single_element_dataset = Subset(dataset, [0])\n",
        "single_data_loader = DataLoader(single_element_dataset, batch_size=1,collate_fn=custom_collate_fn, shuffle=False)\n",
        "train_hybrid_solver(PRE_hybridSolver, correction_net, single_data_loader, optimizer, num_epochs=100, checkpoint_interval=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "t_batch, output_batch=single_element_dataset[0]\n",
        "t_instance = t_batch.squeeze(0)\n",
        "trajectory_gt = output_batch\n",
        "trajectory_gt = [state[1:-1].to(device) for state in trajectory_gt]\n",
        "\n",
        "\n",
        "tN = t_instance[-1]\n",
        "psiInitial = output_batch[1]\n",
        "\n",
        "\n",
        "corrected_traj, solver_t = SOL_hybridSolver(tN,psiInitial,torchsolver.havercampCfun,torchsolver.havercampKfun,torchsolver.havercampthetafun,torchsolver.zeroFun,correction_net)\n",
        "\n",
        "dt = 120.\n",
        "zN = 40.\n",
        "z,t,dts,dz,n,nt,zN,psi,psiB,psiT,pars = torchsolver.setup(dt,tN,zN,psiInitial,torchsolver.havercampSetpars)\n",
        "\n",
        "psiList = torchsolver.fullModelRun(dt,dts,dz,n,nt,psi,psiB,psiT,pars, torchsolver.havercampCfun,torchsolver.havercampKfun,torchsolver.havercampthetafun,0,torchsolver.zeroFun)\n",
        "\n",
        "print(torch.mean(torch.abs(corrected_traj[-1]-trajectory_gt[-1])))\n",
        "print(torch.mean(torch.abs(psiList[-1]-trajectory_gt[-1])))\n",
        "\n",
        "\n",
        "z=np.hstack([0,z,zN])\n",
        "z=z[-1]-z\n",
        "corrected_output = torchsolver.outputWrapper(corrected_traj,0,psiB,psiT)\n",
        "output = torchsolver.outputWrapper(psiList,0,psiB,psiT)\n",
        "\n",
        "\n",
        "fig,ax3 = plt.subplots(figsize=(10, 6))\n",
        "ax3.plot(z, output[-1].detach().numpy(),linestyle=':',linewidth=2.0)\n",
        "ax3.plot(z, corrected_output[-1].detach().numpy(),linestyle=':',linewidth=2.0)\n",
        "#ax3.plot(z, trajectory_gt[-1].detach().numpy(),linestyle=':',linewidth=2.0)\n",
        "'''\n"
      ],
      "metadata": {
        "id": "Ozhu6hlDRseR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-qctp35G1TI"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}