{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import meshplot as mp\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "\n",
    "\n",
    "\n",
    "import torch_mpfd_solver as torchsolver\n",
    "\n",
    "from training_data import generateData\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import ast\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_convert_t(s):\n",
    "    s = s.strip()  # Remove leading/trailing whitespace (including \\r\\n)\n",
    "    s = s.replace(\"\\r\", \"\").replace(\"\\n\", \"\")  # Remove any remaining newline artifacts\n",
    "\n",
    "    match = re.search(r\"tensor\\((\\[.*?\\])\\)\", s)  # Extract only the list part\n",
    "    if match:\n",
    "        return torch.tensor(ast.literal_eval(match.group(1)), dtype=torch.float32)\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected format for t: {s}\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def clean_and_convert_output(s):\n",
    "    s = s.strip()  # Remove leading/trailing whitespace (including \\r\\n)\n",
    "    s = s.replace(\"\\r\", \"\").replace(\"\\n\", \"\")  # Remove newline artifacts\n",
    "\n",
    "    # Extract all array([...]) groups inside the list\n",
    "    matches = re.findall(r\"array\\(\\s*(\\[.*?\\])\", s)  # Find all arrays inside the string\n",
    "    if matches:\n",
    "        # Convert each extracted list into a PyTorch tensor\n",
    "        return [torch.tensor(ast.literal_eval(arr), dtype=torch.float32) for arr in matches]\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected format for output: {s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_at_time(s, t, v):\n",
    "\n",
    "    # If s is before or after the available timepoints, we simply return the end values.\n",
    "    if s <= t[0]:\n",
    "        return v[0] if isinstance(v, list) else v[0]\n",
    "    if s >= t[-1]:\n",
    "        return v[-1] if isinstance(v, list) else v[-1]\n",
    "    \n",
    "    # Find the segment where s lies, i.e. find index i such that t[i] <= s <= t[i+1]\n",
    "    for i in range(len(t) - 1):\n",
    "        if t[i] <= s <= t[i+1]:\n",
    "            # Compute the interpolation factor alpha: 0 when s==t[i], 1 when s==t[i+1]\n",
    "            alpha = (s - t[i]) / (t[i+1] - t[i])\n",
    "            # Use torch.lerp (linear interpolation): lerp(start, end, weight)\n",
    "            if isinstance(v, list):\n",
    "                return torch.lerp(v[i], v[i+1], alpha)\n",
    "            else:\n",
    "                return torch.lerp(v[i], v[i+1], alpha)\n",
    "    \n",
    "    # If s is not within any segment (shouldn't happen), raise an error.\n",
    "    raise ValueError(\"The timepoint s is not within the range of t.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PDETrajectoryDataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file):\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        # Convert the stored strings to proper tensors using your functions:\n",
    "        self.df[\"t\"] = self.df[\"t\"].apply(clean_and_convert_t)\n",
    "        self.df[\"output\"] = self.df[\"output\"].apply(clean_and_convert_output)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        # 'output' is assumed to be a list of tensors representing the PDE trajectory.\n",
    "        trajectory = row[\"output\"]\n",
    "        # h0 is the first element of the ground truth trajectory.\n",
    "        t = row[\"t\"]\n",
    "        # Optionally, you could also return the timepoints if needed (row[\"t\"]).\n",
    "        return t, trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CorrectionCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CorrectionCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=8, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=8, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv1d(in_channels=16, out_channels=12, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv1d(in_channels=12, out_channels=1, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Expect input x shape: (batch, length). Add channel dimension -> (batch, 1, length)\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.conv4(x)\n",
    "        # Remove the channel dimension, returning shape: (batch, length)\n",
    "        x = x.squeeze(1)\n",
    "        return x\n",
    "    \n",
    "    # Utility to count parameters (for verification)\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def SOL_hybridSolver(tN,psiInitial,Cfun,Kfun,thetafun,sink, correction_net):\n",
    "    dt = 120.\n",
    "    zN = 40.\n",
    "    flag = 0\n",
    "    \n",
    "    # Get the traditional solver information ready:\n",
    "\n",
    "    z,t,dts,dz,n,nt,zN,psi,psiB,psiT,pars = torchsolver.setup(dt,tN,zN,psiInitial,torchsolver.havercampSetpars)\n",
    "\n",
    "    psiList = []\n",
    "    psiList +=[psi]\n",
    "\n",
    "    if flag==0:\n",
    "        for j in range(1,nt):\n",
    "            uncorrectedTrajectory = torchsolver.dirichletOneStepModelRun(dts[j-1],dz,n,psiList[j-1],psiB[j-1],psiT[j-1],pars,Cfun,Kfun,thetafun,sink)\n",
    "            h_batch = uncorrectedTrajectory.unsqueeze(0)\n",
    "            correction = correction_net(h_batch)\n",
    "            psiList +=[uncorrectedTrajectory + correction.squeeze(0)]\n",
    "\n",
    "    \n",
    "    return psiList,t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PRE_hybridSolver(tN,psiInitial,Cfun,Kfun,thetafun,sink, correction_net):\n",
    "    dt = 120.\n",
    "    zN = 40.\n",
    "    flag = 0\n",
    "\n",
    "    # Get the traditional solver information ready:\n",
    "\n",
    "    z,t,dts,dz,n,nt,zN,psi,psiB,psiT,pars = torchsolver.setup(dt,tN,zN,psiInitial,torchsolver.havercampSetpars)\n",
    "\n",
    "\n",
    "    psiList = torchsolver.fullModelRun(dt,dts,dz,n,nt,psi,psiB,psiT,pars, Cfun,Kfun,thetafun,flag,sink)\n",
    "\n",
    "    psiList[1:] = [(h + correction_net(h.unsqueeze(0))).squeeze(0) for h in psiList[1:]]\n",
    "\n",
    "    return psiList,t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_hybrid_solver(hybridSolver,correction_net, data_loader, optimizer, num_epochs=10, checkpoint_interval=1):\n",
    "  \n",
    "    correction_net.train()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0.0\n",
    "        \n",
    "        for batch in data_loader:\n",
    "            # Each batch is assumed to be (t, output)\n",
    "            # For a batch_size=1, extract the single instance.\n",
    "            t_batch, output_batch = batch\n",
    "\n",
    "            t_instance = t_batch.squeeze(0)\n",
    "            trajectory_gt = output_batch\n",
    "            trajectory_gt = [state[1:-1] for state in trajectory_gt]\n",
    "            # Extract solver parameters:\n",
    "\n",
    "            tN = t_instance[-1]\n",
    "            psiInitial = output_batch[1]\n",
    "            # --- Call the hybrid solver ---\n",
    "            \n",
    "            corrected_traj, solver_t = hybridSolver(tN, psiInitial, torchsolver.havercampCfun, torchsolver.havercampKfun, torchsolver.havercampthetafun, torchsolver.zeroFun, correction_net)\n",
    "            \n",
    "            # --- Compute the loss ---\n",
    "            # For each time s in the solver's time discretization, interpolate the ground truth\n",
    "            # and compute the MSE with the corrected state.\n",
    "            loss = 0.0\n",
    "            num_steps = len(solver_t)\n",
    "            for j, s in enumerate(solver_t):\n",
    "                # interpolate_at_time returns the ground truth state at time s given the tuple (t_instance, trajectory_gt)\n",
    "                gt_state = interpolate_at_time(s, t_instance, trajectory_gt)\n",
    "                # Compute mean squared error for this time step:\n",
    "                loss += torch.mean((corrected_traj[j] - gt_state) ** 2)\n",
    "            loss = loss / num_steps  # average over all time steps\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss:.4f}\")\n",
    "        \n",
    "        # Save checkpoint.\n",
    "        if (epoch + 1) % checkpoint_interval == 0:\n",
    "            checkpoint_path = f'correction_net_epoch_{epoch+1}.pth'\n",
    "            torch.save(correction_net.state_dict(), checkpoint_path)\n",
    "            print(f\"Saved checkpoint: {checkpoint_path}\")\n",
    "    \n",
    "    final_path = 'correction_net_final.pth'\n",
    "    torch.save(correction_net.state_dict(), final_path)\n",
    "    print(f\"Saved final model weights as {final_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TRAINING ENVIRONMENT ###\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    # If batch size is 1, just return the single tuple instead of a list with one element.\n",
    "    if len(batch) == 1:\n",
    "        return batch[0]\n",
    "    else:\n",
    "        ts, outputs = zip(*batch)\n",
    "        # For 't' assume all samples have the same shape, so you can stack them:\n",
    "        ts = torch.stack(ts, 0)\n",
    "        # 'outputs' will remain a tuple of the ground truth trajectories\n",
    "        return ts, list(outputs)\n",
    "\n",
    "csv_file = \"high_fidelity_training_data.csv\"  # Replace with your CSV file path\n",
    "dataset = PDETrajectoryDataset(csv_file)\n",
    "data_loader = DataLoader(dataset, batch_size=1,collate_fn=custom_collate_fn, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Valde\\OneDrive\\Dokumenter\\GitHub\\PINNs\\torch_mpfd_solver.py:279: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t = torch.hstack([t,torch.tensor(tN)])\n",
      "c:\\Users\\Valde\\OneDrive\\Dokumenter\\GitHub\\PINNs\\torch_mpfd_solver.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  psi = torch.tensor(psiInitial[1:-1], dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 734.9608\n",
      "Saved checkpoint: correction_net_epoch_1.pth\n",
      "Epoch 2/20, Loss: 667.8214\n",
      "Saved checkpoint: correction_net_epoch_2.pth\n",
      "Epoch 3/20, Loss: 662.8495\n",
      "Saved checkpoint: correction_net_epoch_3.pth\n",
      "Epoch 4/20, Loss: 658.2594\n",
      "Saved checkpoint: correction_net_epoch_4.pth\n",
      "Epoch 5/20, Loss: 639.9027\n",
      "Saved checkpoint: correction_net_epoch_5.pth\n",
      "Epoch 6/20, Loss: 649.2512\n",
      "Saved checkpoint: correction_net_epoch_6.pth\n",
      "Epoch 7/20, Loss: 654.6745\n",
      "Saved checkpoint: correction_net_epoch_7.pth\n",
      "Epoch 8/20, Loss: 630.3098\n",
      "Saved checkpoint: correction_net_epoch_8.pth\n",
      "Epoch 9/20, Loss: 616.0691\n",
      "Saved checkpoint: correction_net_epoch_9.pth\n",
      "Epoch 10/20, Loss: 610.6882\n",
      "Saved checkpoint: correction_net_epoch_10.pth\n",
      "Epoch 11/20, Loss: 696.1035\n",
      "Saved checkpoint: correction_net_epoch_11.pth\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[74], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#correction_net.load_state_dict(torch.load(\"correction_net_epoch_9.pth\"))\u001b[39;00m\n\u001b[0;32m      3\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(correction_net\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \u001b[43mtrain_hybrid_solver\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPRE_hybridSolver\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcorrection_net\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[70], line 22\u001b[0m, in \u001b[0;36mtrain_hybrid_solver\u001b[1;34m(hybridSolver, correction_net, data_loader, optimizer, num_epochs, checkpoint_interval)\u001b[0m\n\u001b[0;32m     19\u001b[0m psiInitial \u001b[38;5;241m=\u001b[39m output_batch[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# --- Call the hybrid solver ---\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m corrected_traj, solver_t \u001b[38;5;241m=\u001b[39m \u001b[43mhybridSolver\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpsiInitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorchsolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhavercampCfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorchsolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhavercampKfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorchsolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhavercampthetafun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorchsolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeroFun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorrection_net\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# --- Compute the loss ---\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# For each time s in the solver's time discretization, interpolate the ground truth\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# and compute the MSE with the corrected state.\u001b[39;00m\n\u001b[0;32m     27\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n",
      "Cell \u001b[1;32mIn[69], line 11\u001b[0m, in \u001b[0;36mPRE_hybridSolver\u001b[1;34m(tN, psiInitial, Cfun, Kfun, thetafun, sink, correction_net)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Get the traditional solver information ready:\u001b[39;00m\n\u001b[0;32m      8\u001b[0m z,t,dts,dz,n,nt,zN,psi,psiB,psiT,pars \u001b[38;5;241m=\u001b[39m torchsolver\u001b[38;5;241m.\u001b[39msetup(dt,tN,zN,psiInitial,torchsolver\u001b[38;5;241m.\u001b[39mhavercampSetpars)\n\u001b[1;32m---> 11\u001b[0m psiList \u001b[38;5;241m=\u001b[39m \u001b[43mtorchsolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfullModelRun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdt\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdts\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdz\u001b[49m\u001b[43m,\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnt\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpsi\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpsiB\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpsiT\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43mKfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43mthetafun\u001b[49m\u001b[43m,\u001b[49m\u001b[43mflag\u001b[49m\u001b[43m,\u001b[49m\u001b[43msink\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m psiList[\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;241m=\u001b[39m [(h \u001b[38;5;241m+\u001b[39m correction_net(h\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)))\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m psiList[\u001b[38;5;241m1\u001b[39m:]]\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m psiList,t\n",
      "File \u001b[1;32mc:\\Users\\Valde\\OneDrive\\Dokumenter\\GitHub\\PINNs\\torch_mpfd_solver.py:239\u001b[0m, in \u001b[0;36mfullModelRun\u001b[1;34m(t, dts, dz, n, nt, psi, psiB, psiT, pars, Cfun, Kfun, thetafun, flag, sink)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m flag\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,nt):\n\u001b[1;32m--> 239\u001b[0m         psiList \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[43mdirichletOneStepModelRun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdz\u001b[49m\u001b[43m,\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpsiList\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpsiB\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpsiT\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpars\u001b[49m\u001b[43m,\u001b[49m\u001b[43mCfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43mKfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43mthetafun\u001b[49m\u001b[43m,\u001b[49m\u001b[43msink\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m flag\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,nt):\n",
      "File \u001b[1;32mc:\\Users\\Valde\\OneDrive\\Dokumenter\\GitHub\\PINNs\\torch_mpfd_solver.py:222\u001b[0m, in \u001b[0;36mdirichletOneStepModelRun\u001b[1;34m(dt, dz, n, psi, psiB, psiT, pars, Cfun, Kfun, thetafun, sink)\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdirichletOneStepModelRun\u001b[39m(dt,dz,n,psi,psiB,psiT,pars,Cfun,Kfun,thetafun,sink):\n\u001b[1;32m--> 222\u001b[0m     psiNext \u001b[38;5;241m=\u001b[39m \u001b[43mdirichletIterFun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpsi\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpars\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpsiT\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpsiB\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdt\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdz\u001b[49m\u001b[43m,\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43mCfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43mKfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43mthetafun\u001b[49m\u001b[43m,\u001b[49m\u001b[43msink\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m psiNext\n",
      "File \u001b[1;32mc:\\Users\\Valde\\OneDrive\\Dokumenter\\GitHub\\PINNs\\torch_mpfd_solver.py:190\u001b[0m, in \u001b[0;36mdirichletIterFun\u001b[1;34m(psiin, pars, psiT, psiB, dt, dz, n, Cfun, Kfun, thetafun, sink)\u001b[0m\n\u001b[0;32m    184\u001b[0m dtheta \u001b[38;5;241m=\u001b[39m thetafun(psiiter, pars) \u001b[38;5;241m-\u001b[39m thetafun(psiin, pars)\n\u001b[0;32m    187\u001b[0m R \u001b[38;5;241m=\u001b[39m Rfun(psiiter, psiin, psiT, psiB, C, Kmid, dtheta, dt, dz, n,sink,pars)\n\u001b[1;32m--> 190\u001b[0m dell \u001b[38;5;241m=\u001b[39m \u001b[43msolverfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mKmid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    191\u001b[0m psiout \u001b[38;5;241m=\u001b[39m psiiter \u001b[38;5;241m+\u001b[39m dell\n\u001b[0;32m    192\u001b[0m psiiter \u001b[38;5;241m=\u001b[39m psiout\n",
      "File \u001b[1;32mc:\\Users\\Valde\\OneDrive\\Dokumenter\\GitHub\\PINNs\\torch_mpfd_solver.py:109\u001b[0m, in \u001b[0;36msolverfun\u001b[1;34m(R, C, Kmid, dt, dz, n)\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m theta\n\u001b[0;32m    107\u001b[0m \u001b[38;5;66;03m### SOLVER ###\u001b[39;00m\n\u001b[1;32m--> 109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msolverfun\u001b[39m(R, C, Kmid, dt, dz, n):\n\u001b[0;32m    110\u001b[0m     a \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(n, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m    111\u001b[0m     b \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(n, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "correction_net = CorrectionCNN()\n",
    "#correction_net.load_state_dict(torch.load(\"correction_net_epoch_9.pth\"))\n",
    "optimizer = optim.Adam(correction_net.parameters(), lr=0.01)\n",
    "train_hybrid_solver(PRE_hybridSolver,correction_net, data_loader, optimizer, num_epochs=20, checkpoint_interval=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MINI.TEST ###\n",
    "dt = 120.\n",
    "zN = 40.\n",
    "flag = 0\n",
    "\n",
    "tN = random.randint(360,1440)\n",
    "psiB = random.uniform(-130,-50)\n",
    "psiT = random.uniform(-50,-30)\n",
    "\n",
    "psiInitial = sorted([random.uniform(psiB,psiB) for _ in range(int(zN-1))])\n",
    "psiInitial = np.hstack([psiB,psiInitial,psiT])\n",
    "\n",
    "z,t,dts,dz,n,nt,zN,psi,psiB,psiT,pars = torchsolver.setup(dt,tN,zN,psiInitial,torchsolver.havercampSetpars)\n",
    "\n",
    "\n",
    "psiInitial = torchsolver.dirichletOneStepModelRun(dts[0],dz,n,psi,psiB[0],psiT[0],pars,torchsolver.havercampCfun, torchsolver.havercampKfun, torchsolver.havercampthetafun, torchsolver.zeroFun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pinn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
